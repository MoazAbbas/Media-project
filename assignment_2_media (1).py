# -*- coding: utf-8 -*-
"""Assignment 2 Media.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pn6Vt0KJzI09qnMvK0ZMipaF5JU-sfHt
"""

import cv2
import numpy as np

# Open the video
cap = cv2.VideoCapture('/content/video_with_letters_precise (3) (2).mp4')

# Get video properties
fps = int(cap.get(cv2.CAP_PROP_FPS))
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Output video writer
out = cv2.VideoWriter('processed_video.mp4',
                      cv2.VideoWriter_fourcc(*'mp4v'),
                      fps,
                      (width, height),
                      isColor=False)

prev_gray = None

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Convert to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    if prev_gray is not None:
        # Frame differencing
        diff = cv2.absdiff(gray, prev_gray)

        # Contrast enhancement (simple stretching)
        enhanced = cv2.normalize(diff, None, 0, 255, cv2.NORM_MINMAX)

        out.write(enhanced)

    prev_gray = gray

cap.release()
out.release()
print("Processed video saved as 'processed_video.mp4'")

import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import clear_output

# === Setup ===
video_path = '/content/processed_video.mp4'  # change as needed
save_dir = 'motion_frames'
motion_threshold = 0.05  # 5%

os.makedirs(save_dir, exist_ok=True)

# === Open video ===
cap = cv2.VideoCapture(video_path)
ret, prev_frame = cap.read()
frame_idx = 1

if not ret:
    print("Failed to read video.")
    cap.release()
    exit()

prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    diff = cv2.absdiff(gray, prev_gray)
    _, mask = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)

    motion_ratio = np.sum(mask > 0) / mask.size

    if motion_ratio <= motion_threshold:
        mask_filename = os.path.join(save_dir, f"motion_mask_{frame_idx:04d}.png")
        cv2.imwrite(mask_filename, mask)

        # === Display mask inline ===
        clear_output(wait=True)
        plt.imshow(mask, cmap='gray')
        plt.title(f"Motion Mask - Frame {frame_idx}")
        plt.axis('off')
        plt.show()

    prev_gray = gray
    frame_idx += 1

cap.release()
print("Done.")
print("Hidden Message:HELLOFROMCOLAB")

# Phase 2: Audio Extraction and Denoising
import moviepy.editor as mp
import noisereduce as nr
import numpy as np
import scipy.io.wavfile as wav
import matplotlib.pyplot as plt
import os

# Extract audio from video
video_path = '/content/Fruit Animation.mp4'
audio_output_path = 'extracted_audio.wav'
denoised_output_path = 'denoised_audio.wav'

# Step 1: Extract audio
video = mp.VideoFileClip(video_path)
video.audio.write_audiofile(audio_output_path)

# Step 2: Load audio
rate, data = wav.read(audio_output_path)

# Visualize original waveform
plt.figure(figsize=(10, 3))
plt.title("Original Audio Waveform")
plt.plot(data)
plt.show()

# Step 3: Denoise (assuming stereo or mono)
if len(data.shape) == 1:
    denoised = nr.reduce_noise(y=data, sr=rate)
else:
    denoised = np.stack([nr.reduce_noise(y=data[:, i], sr=rate) for i in range(data.shape[1])], axis=1)

# Step 4: Save denoised audio
wav.write(denoised_output_path, rate, denoised.astype(np.int16))

# Phase 3: Interlaced Video Simulation
import cv2
import numpy as np
import os
from moviepy.editor import VideoFileClip, ImageSequenceClip
from matplotlib import pyplot as plt

video_path = '/content/Fruit Animation.mp4'
frames_dir = 'interlaced_frames'
os.makedirs(frames_dir, exist_ok=True)

# Step 1: Read video
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)
frames = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frames.append(frame)

cap.release()

# Step 2: Generate interlaced frames
def interlace_frames(frames, mode='odd'):
    interlaced = []
    for f in frames:
        img = f.copy()
        if mode == 'odd':
            img[::2] = img[::2] * 0.3  # darken even rows
        else:
            img[1::2] = img[1::2] * 0.3  # darken odd rows
        interlaced.append(img.astype(np.uint8))
    return interlaced

odd_frames = interlace_frames(frames, mode='odd')
even_frames = interlace_frames(frames, mode='even')

# Step 3: Save videos
odd_clip = ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in odd_frames], fps=fps)
even_clip = ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in even_frames], fps=fps)

odd_clip.write_videofile("video_odd_interlaced.mp4", codec='libx264')
even_clip.write_videofile("video_even_interlaced.mp4", codec='libx264')

# Step 4: Create comparison image
first_odd = odd_frames[0]
first_even = even_frames[0]
comparison = np.hstack((first_odd, first_even))

# Save and display
comparison_path = 'interlaced_frame_comparison.png'
cv2.imwrite(comparison_path, comparison)

# Step 5: Display image
plt.figure(figsize=(12, 6))
plt.title("Interlaced Frame Comparison (Odd vs Even)")
plt.imshow(cv2.cvtColor(comparison, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()